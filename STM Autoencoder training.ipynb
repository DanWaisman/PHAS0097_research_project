{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7125e75e",
   "metadata": {},
   "source": [
    "# Unsupervised Classification of STM Images\n",
    "\n",
    "In this notebook we will be training an autoencoder with MNIST images. This model will be saved and later used for future parts of the project.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b232a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from keras import models\n",
    "\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Reshape, UpSampling2D, Dropout, Conv2DTranspose, Activation, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e008a83e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Importing Datasets & Re-shaping Images.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ce75b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing STM Images ###\n",
    "\n",
    "# loading folder\n",
    "path = \"...\"\n",
    "image_folder = [f for f in os.listdir( ... ) if f.endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
    "\n",
    "# ----------- extracting images from folder ----------- #\n",
    "\n",
    "all_images = []\n",
    "\n",
    "for i, image_file in enumerate( image_folder ):\n",
    "    \n",
    "    image_path = os.path.join( path, image_file )\n",
    "    img        = cv2.imread( image_path )\n",
    "    \n",
    "    all_images.append( img )\n",
    "\n",
    "# normalising images\n",
    "all_images = np.array( all_images )\n",
    "all_images = all_images / np.max(all_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24101dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining Datasets ##\n",
    "\n",
    "kTraining_images   = all_images[:600]    # 600\n",
    "kValidation_images = all_images[600:-1]  # 150\n",
    "kTesting_images    = all_images[-1:]     # 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a332986",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Creating and Training the Autoencoder.\n",
    "\n",
    "- No optimisation techniques applied at first.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f66cb8b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Autoencoder Model ###\n",
    "\n",
    "# Needed for decoder #\n",
    "shape_before_flattening = (4, 4, 256)\n",
    "\n",
    "# -------------------------------------------------------------------------------- #\n",
    "\n",
    "input_img_y = Input(shape=(64, 64, 3))\n",
    "\n",
    "# Encoder #\n",
    "y = Conv2D( 32, (3, 3), activation='relu', padding='same', strides=2)(input_img_y)\n",
    "y = Conv2D( 64, (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "y = Conv2D( 128, (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "y = Conv2D( 256, (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "\n",
    "# Latent layers #\n",
    "y = Flatten()(y)\n",
    "y = Dense( 32, activation='relu')(y)\n",
    "y = Dense( np.prod(shape_before_flattening) )(y)\n",
    "y = Reshape( shape_before_flattening )(y)\n",
    "\n",
    "# Decoder #\n",
    "y = Conv2DTranspose( 256, (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "y = Conv2DTranspose( 128, (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "y = Conv2DTranspose( 64, (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "y = Conv2DTranspose( 32, (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "\n",
    "output_y = Conv2DTranspose(3, (3, 3), activation='sigmoid', padding='same')(y)\n",
    "\n",
    "\n",
    "# ----------- Autoencoder model ----------- #\n",
    "autoencoder_y = Model( input_img_y, output_y )\n",
    "autoencoder_y.compile(optimizer=\"adam\",\n",
    "                      loss=\"mean_squared_error\",\n",
    "                      metrics=['mean_squared_error','accuracy'])\n",
    "\n",
    "autoencoder_y.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35159949",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Training model ###\n",
    "\n",
    "history = autoencoder_y.fit( kTraining_images, kTraining_images,\n",
    "                            epochs=150,\n",
    "                            validation_data=( kValidation_images, kValidation_images ));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1992fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOTTING ###\n",
    "\n",
    "# mean squared error data\n",
    "loss = history.history[\"mean_squared_error\"]\n",
    "val_loss = history.history[\"val_mean_squared_error\"]\n",
    "\n",
    "# x axis\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# ---------------------------- Plotting ---------------------------- #\n",
    "\n",
    "fig1 = plt.figure(figsize=(15,7.5))\n",
    "ax2 = fig1.add_subplot(1,1,1)\n",
    "\n",
    "ax2.plot(epochs, loss, \"ro\", label=\"Training\")\n",
    "ax2.plot(epochs, val_loss, \"r\", label=\"Validation\")\n",
    "ax2.legend()\n",
    "ax2.grid()\n",
    "\n",
    "ax2.set_ylabel('Mean squared error')\n",
    "ax2.set_xlabel('Epochs')\n",
    "\n",
    "y_labels = np.arange(0,0.016,0.001)  # Define your labels here\n",
    "ax2.set_yticks(y_labels);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4287cbe9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Testing and Saving model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dc521c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Testing Quality of Autoencoder Reconstruction ###\n",
    "\n",
    "# choosing test images\n",
    "constructed_image = kTesting_images[ 0 ]\n",
    "constructed_image = np.expand_dims( constructed_image, axis=0 )\n",
    "\n",
    "# applying autoencoder model\n",
    "reconstructed_image = autoencoder_y.predict(constructed_image)\n",
    "\n",
    "# -------- plotting --------- #\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1,2,1)\n",
    "ax2 = fig1.add_subplot(1,2,2)\n",
    "\n",
    "ax1.imshow( constructed_image[0] , cmap='gray')\n",
    "ax2.imshow( reconstructed_image[0] , cmap='gray');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75361eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----------------------- SAVING MODEL ----------------------- ###\n",
    "\n",
    "# autoencoder_y.save('autoencoder_model_stm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f639548a",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
