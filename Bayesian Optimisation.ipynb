{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f7f4986",
   "metadata": {},
   "source": [
    "# Bayesian Optimisation\n",
    "\n",
    "In this notebook we carry out bayesian optimisation in order to optimise the dropout rates added to the autoencoder, and hence reduce the overfitting previously observed during training.\n",
    "\n",
    "This notebook should be adapted accordingly for use with the STM or MNIST datasets.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c40795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from keras import models\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Reshape, Conv2D, Conv2DTranspose , Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from hyperopt import fmin , tpe , hp , STATUS_OK , Trials\n",
    "\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5555f46d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step1: Importing the STM dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ce09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing the STM Images ###\n",
    "\n",
    "# loading folder\n",
    "path = \"...\"\n",
    "image_folder = [f for f in os.listdir( ... ) if f.endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
    "\n",
    "# ----------- extracting images from folder ----------- #\n",
    "\n",
    "all_images = []\n",
    "\n",
    "for i, image_file in enumerate( image_folder ):\n",
    "    \n",
    "    image_path = os.path.join( path, image_file )\n",
    "    img        = cv2.imread( image_path )\n",
    "    \n",
    "    all_images.append( img )\n",
    "\n",
    "# normalising images\n",
    "all_images = np.array( all_images )\n",
    "all_images = all_images / np.max(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9f70c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining Datasets ##\n",
    "\n",
    "kTraining_images_stm   = all_images[:600]      # 600\n",
    "kValidation_images_stm = all_images[600:-1]    # 150\n",
    "kTesting_images_stm    = all_images[-1:]       #   1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e272da65",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f425bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing the MNIST Dataset ###\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalisation\n",
    "train_images = train_images / np.max(train_images)\n",
    "test_images  = test_images / np.max(test_images)\n",
    "\n",
    "# Dividing images\n",
    "kTraining_images_mnist   = train_images            # 60,000\n",
    "kValidation_images_mnist = test_images[:5000]      #  5,000\n",
    "kTesting_images_mnist    = test_images[5000:]      #  5,000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c664dad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Re-shaping images.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5445a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Re-shaping Images ###\n",
    "\n",
    "def resize_and_convert( images, shape ):\n",
    "    \n",
    "    images_expanded = tf.expand_dims( images , -1)\n",
    "    \n",
    "    rgb_images = tf.image.grayscale_to_rgb( images_expanded )\n",
    "    \n",
    "    resized_images = tf.image.resize( rgb_images , shape)\n",
    "    \n",
    "    return resized_images\n",
    "\n",
    "# ---------------------------------------------------------- #\n",
    "\n",
    "new_shape = [64, 64]\n",
    "\n",
    "kTraining_images   = resize_and_convert( kTraining_images_mnist,   new_shape )\n",
    "kValidation_images = resize_and_convert( kValidation_images_mnist, new_shape )\n",
    "kTesting_images    = resize_and_convert( kTesting_images_mnist,    new_shape )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a4342",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Defining model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9231883",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def creating_model( params ):\n",
    "    '''\n",
    "    Creating and compiling an Autoencoder Model.\n",
    "    \n",
    "    INPUTS:\n",
    "    - params => parameters to optimize (dropout in this case).\n",
    "    OUTPUTS:\n",
    "    - autoencoder_model => Autoencoder Model Compiled.\n",
    "    '''\n",
    "\n",
    "    # -------------------------- Encoder -------------------------- #\n",
    "    \n",
    "    input_img_y = Input(shape=(64, 64, 3))\n",
    "\n",
    "    y = Conv2D( 32 , (3, 3), activation='relu', padding='same', strides=2)(input_img_y)\n",
    "    y = Dropout( params['dropout_1'] )(y)\n",
    "    y = Conv2D( 64 , (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "    y = Dropout( params['dropout_2'] )(y)\n",
    "    y = Conv2D( 128 , (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "    y = Dropout( params['dropout_3'] )(y)\n",
    "    y = Conv2D( 256 , (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "    y = Dropout( params['dropout_4'] )(y)\n",
    "\n",
    "    # -------------------------- Latent Layers -------------------- #\n",
    "    shape_before_flattening = (4, 4, 256)\n",
    "    \n",
    "    encoder_y = Flatten()(y)\n",
    "    y = Dense( 32 , activation='relu')(encoder_y)\n",
    "    y = Dropout( params['dropout_5'] )(y)\n",
    "    y = Dense(np.prod(shape_before_flattening))(y)\n",
    "    y = Dropout( params['dropout_6'] )(y)\n",
    "    \n",
    "    # -------------------------- Decoder -------------------------- #\n",
    "\n",
    "    y = Reshape(shape_before_flattening)(y)\n",
    "    y = Conv2DTranspose( 256 , (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "    y = Dropout( params['dropout_7'] )(y)\n",
    "    y = Conv2DTranspose( 128 , (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "    y = Dropout( params['dropout_8'] )(y)\n",
    "    y = Conv2DTranspose( 64 , (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "    y = Dropout( params['dropout_9'] )(y)\n",
    "    y = Conv2DTranspose( 32 , (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "    y = Dropout( params['dropout_10'] )(y)\n",
    "\n",
    "    output_y = Conv2DTranspose(3, (3, 3), activation='sigmoid', padding='same')(y)\n",
    "\n",
    "    # ----------- Autoencoder Model ----------- #\n",
    "    \n",
    "    autoencoder_model = Model( input_img_y, output_y )\n",
    "    autoencoder_model.compile(optimizer=\"adam\",\n",
    "                              loss=\"mean_squared_error\",\n",
    "                              metrics=['mean_squared_error','accuracy'])\n",
    "    \n",
    "    return autoencoder_model\n",
    "\n",
    "# ============================================================================== #\n",
    "\n",
    "def objective( params ):\n",
    "    '''\n",
    "    Function which trains a model created by the \"creating model\" function...\n",
    "    ... in order to find the MSE certain parameters result in.\n",
    "    INPUTS:\n",
    "    - params => parameters for which we want to find MSE.\n",
    "    OUTPUTS:\n",
    "    - {'loss': val_MSE, 'status': STATUS_OK} => returns loss and status of model training.\n",
    "    '''\n",
    "    \n",
    "    # Getting model\n",
    "    model = creating_model( params )\n",
    "    \n",
    "    # Training model\n",
    "    history = model.fit( kTraining_images, kTraining_images,\n",
    "                        epochs = 150,\n",
    "                        validation_data = ( kValidation_images, kValidation_images ),\n",
    "                        batch_size = 32,\n",
    "                        verbose = 0)\n",
    "    \n",
    "    # Getting the mean squared error\n",
    "    val_MSE = np.amin( history.history[\"val_mean_squared_error\"] )\n",
    "    \n",
    "    return {'loss': val_MSE, 'status': STATUS_OK}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b339e90",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Bayesian optimisation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cbcd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparametrisation Optimization ###\n",
    "\n",
    "# parameter ranges we're going to test\n",
    "_space_ = {\n",
    "    'dropout_1': hp.uniform('dropout_1', 0.0, 0.5),\n",
    "    'dropout_2': hp.uniform('dropout_2', 0.0, 0.5),\n",
    "    'dropout_3': hp.uniform('dropout_3', 0.0, 0.5),\n",
    "    'dropout_4': hp.uniform('dropout_4', 0.0, 0.5),\n",
    "    'dropout_5': hp.uniform('dropout_5', 0.0, 0.5),\n",
    "    'dropout_6': hp.uniform('dropout_6', 0.0, 0.5),\n",
    "    'dropout_7': hp.uniform('dropout_7', 0.0, 0.5),\n",
    "    'dropout_8': hp.uniform('dropout_8', 0.0, 0.5),\n",
    "    'dropout_9': hp.uniform('dropout_9', 0.0, 0.5),\n",
    "    'dropout_10': hp.uniform('dropout_10', 0.0, 0.5) }\n",
    "\n",
    "# Running the optimization using Hyperopt\n",
    "_trials_ = Trials()\n",
    "\n",
    "# Carries out the optimization\n",
    "best = fmin( fn = objective,\n",
    "            space = _space_,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 50,\n",
    "            trials = _trials_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ba0d24",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
