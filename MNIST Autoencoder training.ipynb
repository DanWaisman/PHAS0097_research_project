{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7125e75e",
   "metadata": {},
   "source": [
    "# Unsupervised Classification of MNSIT\n",
    "\n",
    "In this notebook we will be training an autoencoder with MNIST images. This model will be saved and later used for future parts of the project.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b232a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from keras import models\n",
    "\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Reshape, UpSampling2D, Dropout, Conv2DTranspose, Activation, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style\n",
    "import matplotlib as mpl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e008a83e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Importing Datasets & Re-shaping Images.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec4ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Downloading the MNIST Dataset ###\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalisation\n",
    "train_images = train_images / np.max(train_images)\n",
    "test_images  = test_images / np.max(test_images)\n",
    "\n",
    "# Dividing images\n",
    "kTraining_images_1   = train_images\n",
    "kValidation_images_1 = test_images[:5000]\n",
    "kTesting_images_1    = test_images[5000:]\n",
    "\n",
    "kTraining_labels   = train_labels\n",
    "kValidation_labels = test_labels[:5000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9450ac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Re-shaping Images ###\n",
    "\n",
    "def resize_and_convert( images, shape ):\n",
    "    \n",
    "    images_expanded = tf.expand_dims( images , -1)\n",
    "    \n",
    "    rgb_images = tf.image.grayscale_to_rgb( images_expanded )\n",
    "    \n",
    "    resized_images = tf.image.resize( rgb_images , shape)\n",
    "    \n",
    "    return resized_images\n",
    "\n",
    "# ---------------------------------------------------------- #\n",
    "\n",
    "new_shape = [64, 64]\n",
    "\n",
    "kTraining_images   = resize_and_convert( kTraining_images_1, new_shape )\n",
    "kValidation_images = resize_and_convert( kValidation_images_1, new_shape )\n",
    "kTesting_images    = resize_and_convert( kTesting_images_1, new_shape )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a332986",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Creating and Training the Autoencoder.\n",
    "\n",
    "- No optimisation techniques applied at first.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f66cb8b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Autoencoder Model ###\n",
    "\n",
    "# Needed for decoder #\n",
    "shape_before_flattening = (4, 4, 256)\n",
    "\n",
    "# -------------------------------------------------------------------------------- #\n",
    "\n",
    "input_img_y = Input(shape=(64, 64, 3))\n",
    "\n",
    "# Encoder #\n",
    "y = Conv2D( 32, (3, 3), activation='relu', padding='same', strides=2)(input_img_y)\n",
    "y = Conv2D( 64, (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "y = Conv2D( 128, (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "y = Conv2D( 256, (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "\n",
    "# Latent layers #\n",
    "y = Flatten()(y)\n",
    "y = Dense( 32, activation='relu')(y)\n",
    "y = Dense( np.prod(shape_before_flattening) )(y)\n",
    "y = Reshape( shape_before_flattening )(y)\n",
    "\n",
    "# Decoder #\n",
    "y = Conv2DTranspose( 256, (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "y = Conv2DTranspose( 128, (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "y = Conv2DTranspose( 64, (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "y = Conv2DTranspose( 32, (3, 3), activation='relu', padding='same', strides=2)(y)\n",
    "\n",
    "output_y = Conv2DTranspose(3, (3, 3), activation='sigmoid', padding='same')(y)\n",
    "\n",
    "# ----------- Autoencoder model ----------- #\n",
    "autoencoder_y = Model( input_img_y, output_y )\n",
    "\n",
    "autoencoder_y.compile(optimizer=\"adam\",\n",
    "                      loss=\"mean_squared_error\",\n",
    "                      metrics=['mean_squared_error','accuracy'])\n",
    "\n",
    "autoencoder_y.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c245832",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Training model ###\n",
    "\n",
    "history = autoencoder_y.fit( kTraining_images, kTraining_images,\n",
    "                            epochs=5,\n",
    "                            validation_data=( kValidation_images, kValidation_images ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ffebfc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### PLOTTING ###\n",
    "\n",
    "# mean squared error data\n",
    "loss = history.history[\"mean_squared_error\"]\n",
    "val_loss = history.history[\"val_mean_squared_error\"]\n",
    "\n",
    "# x axis\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# ---------------------------- Plotting ---------------------------- #\n",
    "\n",
    "fig1 = plt.figure(figsize=(15,7.5))\n",
    "ax2 = fig1.add_subplot(1,1,1)\n",
    "\n",
    "ax2.plot(epochs, loss, \"ro\", label=\"Training\")\n",
    "ax2.plot(epochs, val_loss, \"r\", label=\"Validation\")\n",
    "ax2.legend()\n",
    "ax2.grid()\n",
    "\n",
    "ax2.set_ylabel('Mean squared error')\n",
    "ax2.set_xlabel('Epochs')\n",
    "\n",
    "y_labels = np.arange(0,0.016,0.001)  # Define your labels here\n",
    "ax2.set_yticks(y_labels);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3389b959",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Testing and Saving model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dc521c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Testing Quality of Autoencoder Reconstruction ###\n",
    "\n",
    "# choosing test images\n",
    "constructed_image = kTesting_images[ 3 ]\n",
    "constructed_image = np.expand_dims( constructed_image, axis=0)\n",
    "\n",
    "# applying autoencoder model\n",
    "reconstructed_image = autoencoder_y.predict(constructed_image)\n",
    "\n",
    "# ---------------------------- Plotting ---------------------------- #\n",
    "\n",
    "fig1 = plt.figure()\n",
    "\n",
    "ax1 = fig1.add_subplot(1,2,1)\n",
    "ax2 = fig1.add_subplot(1,2,2)\n",
    "\n",
    "ax1.imshow( constructed_image[0] , cmap='gray')\n",
    "ax2.imshow( reconstructed_image[0] , cmap='gray')\n",
    "\n",
    "ax1.set_title('Original')\n",
    "ax2.set_title('Re-constructed');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698ce087",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----------------------- SAVING MODEL ----------------------- ###\n",
    "\n",
    "# autoencoder_y.save('autoencoder_model_mnist')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f639548a",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
